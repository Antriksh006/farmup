{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f09d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/kaggle/input/datas/Crop_recommendation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073bbc43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Separate features and labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_num = \u001b[43mdf\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhumidity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mph\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwater availability\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Encode season\u001b[39;00m\n\u001b[32m      5\u001b[39m season_enc = OneHotEncoder(sparse=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_num = df[[\"temperature\", \"humidity\", \"ph\", \"water availability\"]]\n",
    "\n",
    "# Encode season\n",
    "season_enc = OneHotEncoder(sparse=False)\n",
    "X_season = season_enc.fit_transform(df[[\"season\"]])\n",
    "\n",
    "# Combine numeric + season\n",
    "import numpy as np\n",
    "X = np.hstack([X_num.values, X_season])\n",
    "\n",
    "# Encode labels\n",
    "label_enc = LabelEncoder()\n",
    "y = label_enc.fit_transform(df[\"label\"])\n",
    "\n",
    "# One-hot target\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X[:, :4] = scaler.fit_transform(X[:, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8848cf7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Build model\u001b[39;00m\n\u001b[32m      5\u001b[39m model = tf.keras.Sequential([\n\u001b[32m      6\u001b[39m     tf.keras.layers.Dense(\u001b[32m64\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m, input_shape=(X.shape[\u001b[32m1\u001b[39m],)),\n\u001b[32m      7\u001b[39m     tf.keras.layers.Dropout(\u001b[32m0.3\u001b[39m),\n\u001b[32m      8\u001b[39m     tf.keras.layers.Dense(\u001b[32m32\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      9\u001b[39m     tf.keras.layers.Dense(y.shape[\u001b[32m1\u001b[39m], activation=\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m ])\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(y.shape[1], activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n",
    "\n",
    "# Example prediction\n",
    "sample = np.array([[28, 80, 6.5, 300]])  # numeric values\n",
    "sample_season = season_enc.transform([[\"rainy\"]])\n",
    "sample_input = np.hstack([sample, sample_season])\n",
    "sample_input[:, :4] = scaler.transform(sample_input[:, :4])\n",
    "\n",
    "pred = model.predict(sample_input)\n",
    "print(\"Predicted Crop:\", label_enc.inverse_transform([np.argmax(pred)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d921ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_csv(\"/kaggle/input/data-gov-in/9ef84268-d588-465a-a308-a864a43d0070.csv\")\n",
    "df_filtered = price[price[\"State\"].str.lower() == \"Odisha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Example: Raipur, Chhattisgarh\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "    \"latitude\": 21.25,\n",
    "    \"longitude\": 81.63,\n",
    "    \"hourly\": \"temperature_2m,relative_humidity_2m\",\n",
    "    \"timezone\": \"auto\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, params=params).json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "hourly = pd.DataFrame({\n",
    "    \"date\": pd.to_datetime(resp[\"hourly\"][\"time\"]),\n",
    "    \"temperature_2m\": resp[\"hourly\"][\"temperature_2m\"],\n",
    "    \"humidity_2m\": resp[\"hourly\"][\"relative_humidity_2m\"]\n",
    "})\n",
    "\n",
    "# Derive season from month\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"summer\"\n",
    "    elif month in [6, 7, 8, 9]:\n",
    "        return \"rainy\"\n",
    "    else:\n",
    "        return \"spring\"\n",
    "\n",
    "hourly[\"season\"] = hourly[\"date\"].dt.month.map(get_season)\n",
    "\n",
    "print(hourly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Raipur, Chhattisgarh\n",
    "lat, lon = 21.25, 81.63\n",
    "\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "    \"latitude\": lat,\n",
    "    \"longitude\": lon,\n",
    "    \"current\": \"temperature_2m,relative_humidity_2m,apparent_temperature,is_day,precipitation,\"\n",
    "               \"rain,showers,snowfall,weather_code,cloudcover,pressure_msl,surface_pressure,\"\n",
    "               \"windspeed_10m,winddirection_10m,windgusts_10m\",\n",
    "    \"timezone\": \"auto\",\n",
    "    \"daily\":\"rain_sum\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, params=params).json()\n",
    "\n",
    "# Current weather dict\n",
    "current_weather = resp[\"current\"]\n",
    "\n",
    "# Convert to DataFrame (1-row table)\n",
    "df = pd.DataFrame([current_weather])\n",
    "print(df.T)  # transpose for easier view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2578ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_soil_ph(lat, lon, stat=\"mean\"):\n",
    "    \"\"\"\n",
    "    Query SoilGrids REST API for soil pH in water (phh2o) at a location.\n",
    "    Returns dict: { \"0-5cm\": 8.2, \"5-15cm\": 8.1, ... }\n",
    "    \"\"\"\n",
    "    url = \"https://rest.isric.org/soilgrids/v2.0/properties/query\"\n",
    "    params = {\"lat\": lat, \"lon\": lon, \"property\": \"phh2o\"}\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    out = {}\n",
    "    try:\n",
    "        layers = data[\"properties\"][\"layers\"]\n",
    "        ph_layer = next(layer for layer in layers if layer[\"name\"] == \"phh2o\")\n",
    "        for d in ph_layer[\"depths\"]:\n",
    "            label = d[\"label\"]  # e.g. \"0-5cm\"\n",
    "            val = d[\"values\"].get(stat)\n",
    "            if val is not None:\n",
    "                out[label] = val / 10.0  # convert to real pH\n",
    "    except Exception as e:\n",
    "        print(\"Parse error:\", e)\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lat, lon = 21.25, 81.63\n",
    "    ph_profile = get_soil_ph(lat, lon)\n",
    "    if ph_profile:\n",
    "        print(\"Soil pH profile:\")\n",
    "        for depth, ph in ph_profile.items():\n",
    "            print(f\"  {depth}: {ph:.2f}\")\n",
    "    else:\n",
    "        print(\"No pH data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date, timedelta\n",
    "\n",
    "def get_total_rainfall(latitude, longitude):\n",
    "    # Last 30 days\n",
    "    end_date = date.today()\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "\n",
    "    url = (\n",
    "        f\"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        f\"?latitude={latitude}&longitude={longitude}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&daily=precipitation_sum&timezone=auto\"\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract rainfall values, ignoring None\n",
    "    rainfall_values = [\n",
    "        v for v in data.get(\"daily\", {}).get(\"precipitation_sum\", []) if v is not None\n",
    "    ]\n",
    "    total_rainfall = sum(rainfall_values)\n",
    "\n",
    "    return {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": str(start_date),\n",
    "        \"end_date\": str(end_date),\n",
    "        \"daily_rainfall\": rainfall_values,\n",
    "        \"total_rainfall_mm\": total_rainfall,\n",
    "        \"api_url\": url,\n",
    "    }\n",
    "\n",
    "# Example: Chandigarh, India (30.7333, 76.7794)\n",
    "rainfall_report = get_total_rainfall(30.7333, 76.7794)\n",
    "rainfall_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# ---------- 1. Weather Data ----------\n",
    "def get_weather_summary(lat, lon):\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m\",\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "    resp = requests.get(url, params=params).json()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": pd.to_datetime(resp[\"hourly\"][\"time\"]),\n",
    "        \"temperature_2m\": resp[\"hourly\"][\"temperature_2m\"],\n",
    "        \"humidity_2m\": resp[\"hourly\"][\"relative_humidity_2m\"]\n",
    "    })\n",
    "\n",
    "    avg_temp = df[\"temperature_2m\"].mean()\n",
    "    avg_hum = df[\"humidity_2m\"].mean()\n",
    "\n",
    "    # Season from current date\n",
    "    month = date.today().month\n",
    "    if month in [12, 1, 2]:\n",
    "        season = \"winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        season = \"summer\"\n",
    "    elif month in [6, 7, 8, 9]:\n",
    "        season = \"rainy\"\n",
    "    else:\n",
    "        season = \"spring\"\n",
    "\n",
    "    return avg_temp, avg_hum, season\n",
    "\n",
    "\n",
    "# ---------- 2. Soil pH (first depth only) ----------\n",
    "def get_soil_ph_first(lat, lon, stat=\"mean\"):\n",
    "    url = \"https://rest.isric.org/soilgrids/v2.0/properties/query\"\n",
    "    params = {\"lat\": lat, \"lon\": lon, \"property\": \"phh2o\"}\n",
    "    resp = requests.get(url, params=params).json()\n",
    "\n",
    "    try:\n",
    "        layers = resp[\"properties\"][\"layers\"]\n",
    "        ph_layer = next(layer for layer in layers if layer[\"name\"] == \"phh2o\")\n",
    "        first_depth = ph_layer[\"depths\"][0]  # first depth\n",
    "        val = first_depth[\"values\"].get(stat)\n",
    "        if val is not None:\n",
    "            return val / 10.0\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------- 3. Rainfall ----------\n",
    "def get_total_rainfall(lat, lon):\n",
    "    end_date = date.today()\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "    url = (\n",
    "        f\"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        f\"?latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&daily=precipitation_sum&timezone=auto\"\n",
    "    )\n",
    "    resp = requests.get(url).json()\n",
    "    rainfall_values = [v for v in resp.get(\"daily\", {}).get(\"precipitation_sum\", []) if v is not None]\n",
    "    return sum(rainfall_values)\n",
    "\n",
    "\n",
    "# ---------- 4. Combine into one row ----------\n",
    "def build_single_row(lat, lon, label=\"sample\"):\n",
    "    avg_temp, avg_hum, season = get_weather_summary(lat, lon)\n",
    "    soil_ph = get_soil_ph_first(lat, lon)\n",
    "    rainfall = get_total_rainfall(lat, lon)\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"temperature\": avg_temp,\n",
    "        \"humidity\": avg_hum,\n",
    "        \"ph\": soil_ph,\n",
    "        \"water availability\": rainfall,\n",
    "        \"season\": season,\n",
    "    }])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example: Raipur, Chhattisgarh\n",
    "lat, lon =  26.0909,  81.7131\n",
    "dataset = build_single_row(lat, lon, label=\"raipur_sample\")\n",
    "\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
